# é‡è¦ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§

## ğŸš€ åŸºæœ¬é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd /path/to/llama-lora

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync

# Hugging Faceèªè¨¼ï¼ˆåˆå›ã®ã¿ï¼‰
huggingface-cli login
```

### 2. è¨“ç·´ãƒ»æ¨è«–ãƒ»ãƒãƒ¼ã‚¸ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
```bash
# â‘  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
python scripts/baseline_inference.py

# â‘¡ DoRA/LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œ
python scripts/train.py

# â‘¢ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–ãƒ†ã‚¹ãƒˆ
python scripts/infer.py "å¯Œå£«å±±ã®æ¨™é«˜ã¯ï¼Ÿ"

# â‘£ ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«çµ±åˆï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³åŒ–ï¼‰
python scripts/merge.py
```

## ğŸ”§ é–‹ç™ºãƒ»ãƒ‡ãƒãƒƒã‚°ã‚³ãƒãƒ³ãƒ‰

### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ï¼ˆuvï¼‰
```bash
# ä¾å­˜é–¢ä¿‚ã®åŒæœŸ
uv sync

# æ–°ã—ã„ä¾å­˜é–¢ä¿‚ã®è¿½åŠ 
uv add package_name

# ä¾å­˜é–¢ä¿‚ã®æ›´æ–°
uv lock --upgrade

# ä»®æƒ³ç’°å¢ƒã®ç¢ºèª
uv venv --python 3.12
```

### ã‚³ãƒ¼ãƒ‰å“è³ªç®¡ç†
```bash
# Ruffã«ã‚ˆã‚‹ãƒªãƒ³ãƒ†ã‚£ãƒ³ã‚°
uv run ruff check .

# Ruffã«ã‚ˆã‚‹è‡ªå‹•ä¿®æ­£
uv run ruff check --fix .

# Ruffã«ã‚ˆã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
uv run ruff format .
```

## ğŸ macOS (Darwin) å›ºæœ‰ã‚³ãƒãƒ³ãƒ‰

### MPSç’°å¢ƒè¨­å®š
```bash
# MPSç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
export PYTORCH_ENABLE_MPS_FALLBACK=1
export ACCELERATE_USE_MPS=true

# ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
top -o MEM    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
activity_monitor  # GUIç‰ˆãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒ¼
```

### ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ“ä½œ
```bash
# ãƒ•ã‚¡ã‚¤ãƒ³ãƒ€ãƒ¼ã§é–‹ã
open .
open ./out-llama-lora

# ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
find . -name "*.py" -type f
find . -name "*lora*" -type d

# ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢
grep -r "USE_DORA" scripts/
grep -r "MODEL_ID" . --include="*.py"
```

## ğŸ“Š æ¨è«–ã‚³ãƒãƒ³ãƒ‰è©³ç´°

### åŸºæœ¬æ¨è«–
```bash
# æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
python scripts/infer.py "æ—¥æœ¬èªã§ç°¡æ½”ã«ç­”ãˆã¦ã€‚å¯Œå£«å±±ã®æ¨™é«˜ã¯ï¼Ÿ"

# è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
python scripts/infer.py "What is the height of Mount Fuji?"

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ãæ¨è«–
python scripts/infer.py "Your prompt here" --max_new_tokens 64 --temperature 0.7 --top_p 0.9
```

### ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ
```bash
# ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ç¢ºèª
python scripts/baseline_inference.py

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®æ¯”è¼ƒ
python scripts/infer.py "åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
```

## ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ»é–‹ç™ºæ”¯æ´

### ãƒ­ã‚°ãƒ»å‡ºåŠ›ç¢ºèª
```bash
# è¨“ç·´ãƒ­ã‚°ã®ç¢ºèª
python scripts/train.py 2>&1 | tee training.log

# GPUä½¿ç”¨é‡ç›£è¦–ï¼ˆCUDAç’°å¢ƒï¼‰
nvidia-smi

# ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–
ps aux | grep python
```

### Jupyteré–‹ç™º
```bash
# Jupyterã®èµ·å‹•
uv run jupyter lab

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œ
jupyter nbconvert --execute examples/tiny-llama-dora-test.ipynb
```

## âš¡ ç·Šæ€¥æ™‚ãƒ»ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾å¿œ
```bash
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
python -c "import torch; torch.mps.empty_cache()"

# ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†
pkill -f "python.*train.py"
```

### è¨­å®šãƒªã‚»ãƒƒãƒˆ
```bash
# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªã‚¢
rm -rf ./out-llama-lora

# uvã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
uv cache clean
```

## ğŸ¯ é »ç”¨ã‚³ãƒãƒ³ãƒ‰çµ„ã¿åˆã‚ã›
```bash
# å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
python scripts/train.py && python scripts/infer.py "ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ" && python scripts/merge.py

# å“è³ªãƒã‚§ãƒƒã‚¯å¾Œã®å®Ÿè¡Œ
uv run ruff check --fix . && python scripts/train.py
```